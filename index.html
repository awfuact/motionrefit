<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="Project page for 'Dynamic Motion Blending for Versatile Motion Editing'.">
    <meta property="og:title" content="Dynamic Motion Blending for Versatile Motion Editing"/>
    <meta property="og:description" content="Text-guided motion editing enables high-level semantic control and iterative modifications beyond traditional keyframe animation. Existing methods rely on limited pre-collected training triplets (original motion, edited motion, and instruction), which severely hinders their versatility in diverse editing scenarios. We introduce MotionCutMix, an online data augmentation technique that dynamically generates training triplets by blending body part motions based on input text. While MotionCutMix effectively expands the training distribution, the compositional nature introduces increased randomness and potential body part incoordination. To model such a rich distribution, we present MotionReFit, an auto-regressive diffusion model with a motion coordinator. The auto-regressive architecture facilitates learning by decomposing long sequences, while the motion coordinator mitigates the artifacts of motion composition. Our method handles both spatial and temporal motion edits directly from high-level human instructions, without relying on additional specifications or Large Language Models (LLMs). Through extensive experiments, we show that MotionReFit achieves state-of-the-art performance in text-guided motion editing. Ablation studies further verify that MotionCutMix significantly improves the model's generalizability while maintaining training convergence."/>
    <meta property="og:url" content="https://awfuact.github.io/motionrefit/"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/images/banner_image.jpg" />
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta name="twitter:title" content="Dynamic Motion Blending for Versatile Motion Editing">
    <meta name="twitter:description" content="Text-guided motion editing enables high-level semantic control and iterative modifications beyond traditional keyframe animation. Existing methods rely on limited pre-collected training triplets (original motion, edited motion, and instruction), which severely hinders their versatility in diverse editing scenarios. We introduce MotionCutMix, an online data augmentation technique that dynamically generates training triplets by blending body part motions based on input text. While MotionCutMix effectively expands the training distribution, the compositional nature introduces increased randomness and potential body part incoordination. To model such a rich distribution, we present MotionReFit, an auto-regressive diffusion model with a motion coordinator. The auto-regressive architecture facilitates learning by decomposing long sequences, while the motion coordinator mitigates the artifacts of motion composition. Our method handles both spatial and temporal motion edits directly from high-level human instructions, without relying on additional specifications or Large Language Models (LLMs). Through extensive experiments, we show that MotionReFit achieves state-of-the-art performance in text-guided motion editing. Ablation studies further verify that MotionCutMix significantly improves the model's generalizability while maintaining training convergence.">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/twitter_banner_image.jpg">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="motion editing, motion from instruction">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Dynamic Motion Blending for Versatile Motion Editing</title>
    <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="static/css/index.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/video-gallery.css">
    <link rel="stylesheet" href="static/css/grid.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="https://kit.fontawesome.com/d383128d10.js" crossorigin="anonymous"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
    <script src="static/js/video-gallery.js"></script>
    <script src="static/js/grid.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Dynamic Motion Blending for Versatile Motion Editing</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
                            <a href="https://jnnan.github.io/" target="_blank">Nan Jiang</a><sup>1,2*</sup>&nbsp&nbsp&nbsp&nbsp
                        </span>
                        <span class="author-block">
                            <a href="https://awfuact.github.io/" target="_blank">Hongjie Li</a><sup>1*</sup>&nbsp&nbsp&nbsp&nbsp
                        </span>
                        <span class="author-block">
                            <a href="https://pku.ai/author/ziye-yuan/" target="_blank">Ziye Yuan</a><sup>1*</sup>&nbsp&nbsp&nbsp&nbsp
                        </span>
                        <span class="author-block">
                            <a href="https://mileret.github.io/" target="_blank">Zimo He</a><sup>1,2,3</sup>&nbsp&nbsp&nbsp&nbsp
                        </span>
                        <br>
                        <span class="author-block">
                            <a href="https://yixchen.github.io/" target="_blank">Yixin Chen</a><sup>2</sup>&nbsp&nbsp&nbsp&nbsp
                        </span>
                        <span class="author-block">
                            <a href="https://tengyu.ai/" target="_blank">Tengyu Liu</a><sup>2</sup>&nbsp&nbsp&nbsp&nbsp
                        </span>
                        <span class="author-block">
                            <a href="https://yzhu.io/" target="_blank">Yixin Zhu</a><sup>1✉️</sup>&nbsp&nbsp&nbsp&nbsp
                        </span>
                        <span class="author-block">
                            <a href="https://siyuanhuang.com/" target="_blank">Siyuan Huang</a><sup>2✉️</sup>&nbsp&nbsp&nbsp&nbsp
                        </span>
                    </div>
                    <div class="is-size-6 publication-authors">
                        <!-- Affiliations -->
                        <span class="author-block">
                            <sup>1</sup>Institute for AI, Peking University &nbsp&nbsp 
                            <sup>2</sup>State Key Laboratory of General Artificial Intelligence, BIGAI
                            <br>
                            <sup>3</sup>Yuanpei College, Peking University &nbsp&nbsp <sup>*</sup>Equal Contributions &nbsp&nbsp <sup>✉️</sup> Corresponding Authors
                        </span>
                    </div>
                    <div class="is-size-4 publication-authors" style="padding:1.5%;">
                        <!-- Conference -->
                        <span class="author-block">
                            <font color="#008FFF">CVPR 2025</font>
                        </span>
                    </div>
                    <div class="column has-text-centered" style="padding-top:0;">
                        <div class="publication-links">
                            <!-- Arxiv PDF link -->
                            <span class="link-block">
                                <a href="" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                    <span>Paper</span>
                                </a>
                            </span>
            
                            <!-- ArXiv Abstract Link -->
                            <span class="link-block">
                                <a href="" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                                    <span>arXiv</span>
                                </a>
                            </span>
            
                            <!-- Code link -->
                            <span class="link-block">
                                <a href="" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fab fa-github"></i></span>
                                    <span>Code</span>
                                </a>
                            </span>
            
                            <!-- Data link -->
                            <span class="link-block">
                                <a href="" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fa-solid fa-download"></i></span>
                                    <span>Data</span>
                                </a>
                            </span>

                            <!-- Demo link -->
                            <span class="link-block">
                                <a href="https://huggingface.co/spaces/Yzy00518/motionReFit" class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon"><i class="fa-solid fa-gamepad"></i></span>
                                    <span>Live Demo</span>
                                </a>
                              </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Teaser -->
<section class="hero teaser">
    <div class="hero-body">
        <div class="container">
            <figure class="image" style="margin-bottom: 0;">
                <img src="static/images/teaser.jpg" alt="Research Poster">
                <figcaption class="mt-3">
                    MotionReFit enables seamless spatial and temporal motion edits through textual instructions. Powered by our MotionCutMix training strategy, MotionReFit leverages abundant unannotated motion data to augment scarce editing triplets, enabling robust and generalizable editing across diverse scenarios.
                </figcaption>
            </figure>
        </div>
    </div>
</section>
<!--End teaser -->


<!-- Interactive modification -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-2" style="margin-bottom: 0;">Interactive Motion Editing</h2>
            <div class="video-gallery-carousel-container">
                <div class="video-gallery-carousel" id="gallery-carousel-long">
                    <div class="video-single active">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/long.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
            </div>
            <figure class="image" style="margin-bottom: 0rem;">
                <figcaption class="mt-3">
                    MotionReFit supports interactive motion modification by using previously edited motions as input for subsequent processes. Users can build upon earlier edits by feeding the modified motion back into the model with new prompts.
                </figcaption>
            </figure>
        </div>
    </div>
</section>
<!--End interactive modification -->


<!-- Youtube video -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-2" style="margin-bottom: 1rem;">Overview Video</h2>
                <div class="publication-video">
                    <iframe src="https://www.youtube.com/embed/p7HN1LVCRaQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                </div>
            </div>
        </div>
    </div>
  </section>
  <!-- End youtube video -->


<!-- Body part replacement -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-2" style="margin-bottom: 0;">Results on Body Part Replacement</h2>

            <div class="video-gallery-carousel-container">
                <!-- Navigation arrows -->
                <button class="nav-arrow prev-arrow" id="gallery-carousel-replacement-prev">&#10094;</button>
                <div class="video-gallery-carousel" id="gallery-carousel-replacement">
                    <div class="video-single active">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/replacement_1.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>

                    <div class="video-single">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/replacement_2.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>

                    <div class="video-single">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/replacement_3.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="video-single">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/replacement_4.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
                <!-- Navigation arrow -->
                <button class="nav-arrow next-arrow" id="gallery-carousel-replacement-next">&#10095;</button>
            </div>
            <div class="gallery-dots" id="gallery-carousel-replacement-dots">
                <!-- Dots will be added dynamically via JavaScript -->
            </div>
        </div>
    </div>
</section>
<!--End body part replacement -->


<!-- Style transfer -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-2" style="margin-bottom: 0;">Results on Style Transfer</h2>

            <div class="video-gallery-carousel-container">
                <!-- Navigation arrows -->
                <button class="nav-arrow prev-arrow" id="gallery-carousel-style-prev">&#10094;</button>
                <div class="video-gallery-carousel" id="gallery-carousel-style">
                    <div class="video-single active">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/style_1.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>

                    <div class="video-single">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/style_2.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>

                    <div class="video-single">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/style_3.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="video-single">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/style_4.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
                <!-- Navigation arrow -->
                <button class="nav-arrow next-arrow" id="gallery-carousel-style-next">&#10095;</button>
            </div>
            <div class="gallery-dots" id="gallery-carousel-style-dots">
                <!-- Dots will be added dynamically via JavaScript -->
            </div>
        </div>
    </div>
</section>
<!--End style transfer -->


<!-- Fine-grained adjustment -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-2" style="margin-bottom: 0;">Results on Fine-grained Adjustment</h2>

            <div class="video-gallery-carousel-container">
                <!-- Navigation arrows -->
                <button class="nav-arrow prev-arrow" id="gallery-carousel-adjustment-prev">&#10094;</button>
                <div class="video-gallery-carousel" id="gallery-carousel-adjustment">
                    <div class="video-single active">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/adjustment_1.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>

                    <div class="video-single">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/adjustment_2.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>

                    <div class="video-single">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/adjustment_3.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    
                    <div class="video-single">
                        <div class="video-container">
                            <video preload="auto" controls muted loop playsinline height="100%">
                                <source src="static/videos/adjustment_4.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
                <!-- Navigation arrow -->
                <button class="nav-arrow next-arrow" id="gallery-carousel-adjustment-next">&#10095;</button>
            </div>
            <div class="gallery-dots" id="gallery-carousel-adjustment-dots">
                <!-- Dots will be added dynamically via JavaScript -->
            </div>
        </div>
    </div>
</section>
<!--End fine-grained adjustment -->


<!-- Paper abstract -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-2" style="margin-bottom: 0.5rem;">Abstract</h2>
            <figure class="image" style="margin-bottom: 0rem;">
                <figcaption style="margin-top: 0rem;">
                    Text-guided motion editing enables high-level semantic control and iterative modifications beyond traditional keyframe animation. Existing methods rely on limited pre-collected training triplets (original motion, edited motion, and instruction), which severely hinders their versatility in diverse editing scenarios. We introduce MotionCutMix, an online data augmentation technique that dynamically generates training triplets by blending body part motions based on input text. While MotionCutMix effectively expands the training distribution, the compositional nature introduces increased randomness and potential body part incoordination. To model such a rich distribution, we present MotionReFit, an auto-regressive diffusion model with a motion coordinator. The auto-regressive architecture facilitates learning by decomposing long sequences, while the motion coordinator mitigates the artifacts of motion composition. Our method handles both spatial and temporal motion edits directly from high-level human instructions, without relying on additional specifications or Large Language Models (LLMs). Through extensive experiments, we show that MotionReFit achieves state-of-the-art performance in text-guided motion editing. Ablation studies further verify that MotionCutMix significantly improves the model's generalizability while maintaining training convergence.
                </figcaption>
            </figure>
        </div>
    </div>
</section>
<!-- End paper abstract -->


<!-- Method -->
<section class="hero is-small">
  <div class="hero-body">
        <div class="container">
            <h2 class="title is-2" style="margin-bottom: 1rem;">Method Overview</h2>
            <div class="video-caption" style="padding:0;"><b>MotionRefit</b></div>
            <figure class="image" style="margin-bottom: 1rem;">
                <img src="static/images/method.png" alt="Research Poster">
                <figcaption class="mt-3">
                    MotionRefit processes the original motion through sliding windows, where body keypoints are encoded for input to a transformer-based motion diffusion model. To ensure motion continuity, noise is applied starting from the third frame while preserving the first two frames. The model incorporates an additional token integrating the editing instruction, diffusion step, and progress indicator. The generated keypoints undergo SMPL-X optimization and merging to create the final edited motion. To enhance body part coordination, we employ a discriminator trained to identify motion segments composed of multiple source motions, which guides the denoising process through classifier guidance.
                </figcaption>
            </figure>
            <div class="video-caption" style="padding:0;"><b>Spatial Motion Blending</b></div>
            <figure class="image" style="margin-bottom: 0;">
                <img src="static/images/compose.png" alt="Research Poster" style="width:50%;margin-left:auto;margin-right:auto;">
                <figcaption class="mt-3">
                    Spatial motion blending enables seamless integration of different motions across body parts. We compare hard versus soft masking, showing how soft masks produce smoother transitions and eliminate boundary artifacts.
                </figcaption>
            </figure>
        </div>
  </div>
</section>
<!--End method -->


<!-- Dataset -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-2" style="margin-bottom: 1rem;">The STANCE Dataset</h2>
            <figure class="image" style="margin-bottom: 0;">
                <img src="static/images/dataset.png" alt="Research Poster">
                <figcaption class="mt-3">
                Sample sequences from our STANCE dataset. Our work introduces three complementary datasets: (a) a body part replacement dataset comprising 13,000 sequences from HumanML3D, annotated with an average of 2.1 body masks and corresponding motion descriptions; (b) a motion style transfer dataset containing 2 hours of new MoCap recordings that recreate HumanML3D sequences in various styles; and (c) a fine-grained motion adjustment dataset featuring 16,000 annotated triplets of generated motion pairs with their corresponding descriptions.
                </figcaption>
            </figure>
        </div>
    </div>
</section>
<!--End Dataset -->


<!-- BibTex citation -->
 <!-- <section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <h2 class="title is-2" style="margin-bottom: 1rem;">BibTex</h2>
            <figure class="image" style="margin-bottom: 0;">
                <pre><code>@article{li2024zerohsi,
  title={ZeroHSI: Zero-Shot 4D Human-Scene Interaction by Video Generation},
  author={Li, Hongjie and Yu, Hong-Xing and Li, Jiaman and Wu, Jiajun},
  journal={arXiv preprint arXiv:2412.18600},
  year={2024}
}</code></pre>
            </figure>
        </div>
    </div>
</section> -->
<!--End BibTex citation -->


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content has-text-centered">
                    <p>
                        This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                        <br>
                        This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>


</body>
</html>
